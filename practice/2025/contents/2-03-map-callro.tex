\section{Дизайн-документ по реализации функционала Map-Reduce по репликам}

\begin{itemize}
    \item Текущая реализация Map запроса по репликам у клиента ведет к
    дублированию, потере и повреждению данных;
    \item В vshard будут добавлены новые запросы: \textit{map_callro},
        \textit{map_callre}, \textit{map_callbro}, \textit{map_callbre};
    \item \textit{map_*} запросы (даже те, которые выполняются на репликах)
        замедляют ребалансировку. Пользователь может регулировать распределение
        между map запросами и перевозом бакетов с использованием опций
        sched_ref_quota, sched_move_quota.
\end{itemize}

\subsection{Мотивация}

В бизнес-логике клиента очень много map-запросов, однако \textit{vshard} на
данный момент не предлагает никакого решения для совершения map-запросов по
репликам, вследствии чего клиент вынужден писать собственные решения с
использованием \textit{vshard.router.routeall}, которые выполняются с рисками
нарушения консистентности и целостности получаемых данных (дублирование и
потеря).

Базово сейчас \textit{map_callro} у клиента выглядит так (еще есть логика на
пропуск репликасетов из \textit{routeall} при определенных условиях):

\begin{verbatim}
for _, rs in pairs(vshard.router.routeall()) do
    rs:callbro('box.space.card:select()', nil, {timeout = <number>})
end
\end{verbatim}

Это крайне небезопасно:

\begin{enumerate}
\item \textbf{Дублирование данных} - бакет может находиться в процессе
    пересылки (\textit{state = SENDING}) или уже даже быть послан
        (\textit{state = SENT}). Данные не удаляются во время пересылки, только
        после ее полного окончания, поэтому когда бакет переезжает данные есть
        на двух шардах. При \textit{select} по спейсу получим дублирование
        данных. Даже если бакет полностью переехал, дублирование возможно:
        пришли на первый репликасет, там данные еще есть, пока идем до второго,
        они переехали, пришли на второй, там эти же данные уже есть. Если бакет
        в процессе удаления, то можно прочитать часть бакета, а полностью он
        будет только там, куда уехал, снова дублирование.

\item \textbf{Потеря данных} - мы идем на первый репликасет, данных там пока
    нет, нам вернули результат. Пока идем до следующего, он успевает переслать
        бакет на первый репликасет (полностью переслать, с удалением данных).
        Мы дошли до него, данных там тоже не будет. Map-запрос потерял данные.

\item \textbf{"Повреждение данных"} - можно прочитать неконсистентное состояние
    данных (\textit{state = GARBAGE}). Допустим пользователь добавлял в один
        бакет в одной транзакции таплы 1, 2, 3, 4, 5. Бакет уехал. Таплы 1, 2,
        3 уже удалились. Таплы 4 и 5 еще нет. Запрос их прочитает, т.е.
        половину пользовательской транзакции.

\end{enumerate}

\textit{Vshard}-у следует предоставить собственное решение для выполнения
map-запроса по репликам, который не будет дублировать и терять бакеты.

\subsection{Текущая работа Map запроса по мастерам (map_callrw)}

\texttt{vshard.router.map_callrw} принимает в качестве аргумента функцию,
которая вызывается на мастерах в кластере с гарантией, что в случае успешного
выполнения она была выполнена при доступности всех бакетов для чтения и записи.
Под консистентностью в рамках Map-Reduce понимается, что все данные были
доступны и не перемещались в процессе выполнения запросов Map. Чтобы сохранить
консистентность, добавлена третья стадия - Ref. Таким образом, алгоритм на
самом деле называется Ref-Map-Reduce.

Ref-ы отправляются до этапа Map, чтобы закрепить бакеты на репликасетах и
гарантировать, что они не будут перемещаться до завершения стадии Map. Если
хотя бы один Ref не удалось проставить, то пользователю возвращается ошибка.

Если все Ref-ы успешно завершены, начинается рассылка запросов Map. Эти запросы
выполняют пользовательскую функцию и после удаляют Ref-ы, чтобы снова разрешить
ребалансировку. Рассылка запросов Map производится параллельно, ко всем
необходимым мастерам.

На уровне стораджей существуют дополнительные механизмы, чтобы гарантировать,
что Map-Reduce не блокирует ребалансировку навсегда и наоборот: что
ребалансировка не заблокирует полностью Map-Reduce. Это конкурирующие процессы.
В vshard есть опции: \texttt{sched_ref_quota}, \texttt{sched_move_quota}. Если
\texttt{move_quota = 2} и \texttt{ref_quota = 15}, то это означает, что
максимум 2 бакета могут переехать, если есть запросы на ref. И наоборот,
максимум 15 рефов может быть сделано, если нужно перевозить бакет.

Подробней про работу \texttt{map_callrw} можно прочитать в дизайн-документе
соответсвующем дизайн-документе \cite{MapCallrwRfc}.

Аргументы vshard.router.map_callrw:

\begin{itemize}
\item \texttt{func}: Имя вызываемой функции.
\item \texttt{args}: Аргументы функции, переданные в формате netbox (в виде
    массива).
\item \texttt{opts}: Опции. Подробности ниже:
\begin{itemize}
\item \texttt{timeout}: Таймаут в секундах. Учтите, что Ref-ы могут оставаться
    на хранилищах в течение всего этого таймаута, если что-то пойдет не так,
        например, возникнут сетевые проблемы. Поэтому лучше не использовать
        значение больше, чем необходимо.
\item \texttt{return_raw}: true/false. Если указано, возвращаемые значения не
    декодируются в нативные объекты Lua и остаются упакованными как объект
        msgpack (см. модуль msgpack). По умолчанию все значения декодируются.
        Это может быть нежелательно, если возвращаемые значения будут сразу
        пересылаться по сети.
\item \texttt{bucket_ids}: Массив ID бакетов, которые должны быть охвачены
    Map-Reduce. Если она указана, Map-Reduce выполняется только на мастерах,
        содержащих хотя бы один из этих бакетов. В противном случае Map-Reduce
        выполняется на всех мастерах кластера.
\end{itemize}
\end{itemize}

\subsection{Дизайн}

В map-запросах все фазы Ref-Map выполняются на одной и той же реплике:

\begin{itemize}
\item \texttt{map_callrw} -- выполняется только на мастере. Реализован в
    текущей версии.

\item \texttt{map\_callro} -- реплика выбирается на основе весов в конфигурации
    роутера (чем меньше вес, тем реплика приоритетнее). Такой репликой может
        являться и мастер (при использовании весов по умолчанию мастер является
        наиболее приоритетной репликой). Выбор реплики не является постоянным и
        может временно меняться, если самая приоритетная реплика недоступна.

\item \texttt{map\_callre} -- предпочтение отдается не мастеру (но все еще
    может быть выполнена на мастере как последняя мера, если все реплики не
        ответили).

\item \texttt{map\_callbro} -- round-robin балансировка по всем инстансам в
    репликасете, может быть как мастер, так и реплика.

\item \texttt{map\_callbre} -- round-robin балансировка, но с предпочтением
    пропускать мастера.
\end{itemize}

\subsubsection{Ref стадия запроса}

Для map запросов по репликам применяются те же рефы, что используются сейчас
для мастеров, ref полностью локальный (если инстанс не мастер, то запрос на
мастера не совершается). Реф происходит до запроса ко всем репликам, в
отдельную фазу, как и для \texttt{map\_callrw}. Ref так же как и в случае c
\texttt{map\_callrw} дожидается, чтобы все бакеты на инстансе были
\texttt{ACTIVE} или \texttt{PINNED}. Если не получается зарефать (идет
ребалансировка), возвращается ошибка, ни один map запрос не будет выполнен.
Если ref успешно создан на всех репликах, выполняется пользовательская функция,
после чего реф удаляется.

Ref блокирует все бакеты на инстансе, пока висит Ref, ребалансировка
невозможна.

\subsubsection{Map запросы и ребалансировка бакетов}

Мастеру приходит запрос на перевоз N бакетов. Он собирает эти N бакетов и перед
началом отправления делает \texttt{sched.move_start} локально. В случае успеха
мастер переводит бакеты в состояние \texttt{SENDING}. Далее, данные не
отправляются/получаются, пока мы не получим на это разрешение всех реплик в
нашем репликасете. Мастер дожидается на каждой из реплик выполнение функции
\texttt{bucket_move_prepare_replica(timeout, vclock_of_first_bucket)}, где
\texttt{vclock} -- это vclock мастера после того, как был изменен статус
первого измененного бакета. Эта функция выполняется на реплике следующим
образом:

\begin{itemize}
\item Вызывает \texttt{sched.move_start} чтобы создать конкуренцию за ресурсы
    на репликах и обеспечить заданное пользователем (с помощью
        \texttt{sched_*_quota} опций) распределение между перевозом бакетов и
        ref запросами.
\item Дожидается, чтобы реплика достигла необходимого vclock. Т.е. получила
    хотя бы один \texttt{SENDING} бакет. Этого достаточно, чтобы новые рефы не
        могли быть созданы и ждать, пока отреплицируются все, смысла ждать нет.
\item Вызывает \texttt{sched.move_end(1)}. Отныне новые рефы не могут быть
    созданы, так как бакет перемещается.
\end{itemize}

Если хотя бы одна реплика ответила ошибкой, бакеты не будут посылаться, ошибка
отправления бакета. Не меняем состояние бакета, в случае ошибок этим занимается
recovery (не забыть разбудить в случае фейла) и gc. Если все реплики смогли
подтвердить перевоз бакетов, то обращаемся к мастеру, на который данные будут
отправляться: \texttt{bucket_recv_prepare_master(timeout, buckets)}. Он
переводит бакеты в состояние \texttt{RECEIVING}, делает вызов по репликам
\texttt{bucket_move_prepare_replica}, чтобы убедиться, что новые рефы не смогут
быть созданы и дождаться окончания \texttt{map_callro}. Если успешно,
возвращает ок.

Вся работа мастера, описанная выше объединяется в функцию
\texttt{bucket_send_prepare_master(timeout, buckets)}.

Таким образом на посылку/получение одного батча (откуда посылаем: батч - все
route, которые пришли, куда посылаем: батч - набор бакетов от конкретного
репликасета) нужно будет совершить только по одному запросу на каждую из
реплик. Дальше при пересылке бакетов работают воркеры, как обычно (но не
переводя в состояние \texttt{SENDING} и то, что описано выше).

Чтобы предотвратить одновременную посылку одного и того же бакета (например,
когда ребалансер пытается послать и пользователь вызывает
\texttt{bucket_send}), \texttt{M.rebalancer_transfering_buckets[bid] =
'preparing'} выполняется для каждого из бакетов перед локальным
\texttt{sched_move_start} на мастере (в самом начале
\texttt{bucket_send_prepare_master}). Затем когда воркер начинает работу он
проверяет, что статус бакета \texttt{preparing} (можно было бы добавить статус
\texttt{prepared} после того, как дождались разрешения реплик, но выглядит
бессмысленно, мы не должны отдавать работу в воркеры, если бакет не разрешили
пересылать), меняет его в \texttt{transfering}. На принимающей стороне
состояние бакета меняется на \texttt{preparing} в
\texttt{bucket_recv_prepare_master} (recovery должен разруливать эти статусы и
подчищать их, если на отправляющей стороне
\texttt{rebalancer_transfering_buckets} в \texttt{nil}). На стадии
\texttt{bucket_recv} состояние бакета меняется на \texttt{transfering}. По
умолчанию \texttt{M.rebalancer_transfering_buckets[bid] = nil}.

Если \texttt{bucket_recv} видит, что бакета не существует, тогда он вызывает
\texttt{bucket_move_prepare_replica}. Необходимо, чтобы ребалансинг работал,
если отправитель на старой версии, а получатель на новой. Если отправитель на
новой версии, то пересылка бакета будет падать на стадии
\texttt{bucket_recv_prepare_master}.

\subsection{Последующе действия}

Описанное в данном пункте будет реализовано только по запросу от пользователей.
В изначальную имплементацию map запросов этот пункт не входит.

Во все \texttt{map\_*} запросы добавляется новая опция
\texttt{consistency\_coverage\_mode}. При обоих режимах выполняется попытка
остановить ребалансировку!

\begin{itemize}
    \item \texttt{consistency\_coverage\_mode = 'full'}. Запрос будет выполнен
        везде или не будет выполнен вовсе, запрос гарантированно будет без
        дублирования данных, без их потери, т.е. будет выполнен на каждом
        бакете и ровно один раз.

    \texttt{map\_*} запрос выполняется в две фазы: Ref - попытка приостановить
        ребалансировку на всех инстансах, Map - выполнение пользовательской
        функции. Необходим в первую очередь для \texttt{map\_callrw}. Если
        ошибка на стадии Ref - возврат ошибки пользователю, функция не будет
        исполнена нигде.

    \item \texttt{consistency\_coverage\_mode = 'accidental'}. Запрос будет
        выполнен там, где удастся остановить ребалансировку. Там, где он
        выполнится, дублирования данных не будет, т.е. функция не будет
        исполнена дважды на одном и том же бакете, "not more than once". Но
        данные в рамках кластера могут быть частично прочитаны и записаны, нет
        гарантии "at least once" для каждого из бакетов.

    \texttt{map\_*} запрос тоже выполняется в две фазы. Единственное отличие от
        \texttt{full} режима: если на стадии Ref не удалось выполнится на всех
        инстансах, то стадия Map выполняется на тех инстансах, где Ref прошел
        успешно. Всегда возвращается таблица типа \texttt{\{<replicaset\_uuid>
        = <returned\_value>, ...\}}.

    Полезен при \texttt{map\_*} запросах на чтение.
\end{itemize}

Первый режим необходим для работы \texttt{map\_callrw}. Необходимо
гарантировать, что запрос выполнен на всех репликасетах, а не на их части. Ибо
если мы записали что-то только на части репликасетов, то это беда, частичное
обновление данных. Однако, если пользователь, например, читает только с
мастеров (например, для обеспечения максимальной согласованности данных), то
имеет смысл использовать \texttt{accidental}.

Второй режим будет очень полезен для \texttt{map\_callro}, так как в
большинстве случаев лучше прочитать хоть что-то (например делаем select по
спейсу), чем не читать вообще ничего. Однако если данные невозможно
использовать частично, \texttt{consistency\_coverage\_mode} все равно должен
стоять в \texttt{full}.

Режим \texttt{full} существует уже сейчас в \texttt{map\_callrw}. Будет
добавлен только \texttt{accidental}. Для map запросов по репликам в изначальной
имплементации реализовываем только \texttt{full} режим, \texttt{accidental}
добавляется в тикет.

\subsection{Рассмотренные альтернативы}

\subsubsection*{Вызывать sched.move\_start на репликах перед изменением состояния бакета}

Была идея, чтобы перед отправлением/получением бакета, до изменения состояния
бакета совершать \texttt{sched.move\_start}. Только если сумели дождаться 0
рефов везде, можно начинать ребалансировку, производится перевод бакета в
нужное состояние на мастере, бакет перевозится. Реплика автоматически зовет
\texttt{sched.move\_end} в on\_replace триггере когда получает по репликации
\texttt{replace} в \texttt{\_bucket}. Если же где-то есть рефы и мы не смогли
дождаться, то отменяем все с помощью \texttt{sched.move\_end} с мастера.

Однако тут мы наблюдаем стандартную проблему 2PC. Если мы не используем
таймаут, после которого автоматически зовется \texttt{sched.move\_end}, то,
если мастер падает сразу после вызова \texttt{sched.move\_start}, реплика
навсегда заблокирована. Если мы используем таймауты, то можем получить
неконсистентные данные, так как таймаут может отработать раньше, чем придет
replace в \_bucket, будет создан ref для map\_call, а потом к нам долетит
replace: во время исполнения функции пользователя мы нарушили гарантии того,
что состояние бакетов не будет меняться.

\subsection*{При посылке бакета разрешать рефать реплику}

Была идея разрешить рефать реплики, пока бакет находится в состоянии
\texttt{SENDING}. Появляется новый тип глобального рефа (определенного в модуле
ref.lua): \texttt{ref.add\_ro}, старый переименовывается в
\texttt{ref.add\_rw}. В отличии от текущего rw ref-а он ждет, чтобы все бакеты
были читаемыми (т.е. \texttt{ACTIVE}, \texttt{PINNED}, или \texttt{SENDING}).
Именно этим глобальным рефом и пользуются реплики при map\_call.

В случае отправления бакета. Переводим бакет в состояние \texttt{SENDING},
начинаем отправлять. Читать \texttt{SENDING} бакеты можно. Он не будет удален,
пока существуют рефы на этот бакет, однако нужно заставить gc учитывать ro рефы
на стораджах. Поведение такое же, как для обычных call запросов: могут
существовать рефы, даже если бакет в состоянии \texttt{SENT}, \texttt{GARBAGE}.

В случае получения бакета (\texttt{RECEIVING}) рефать такой сторадж запрещено,
мастер дожидается 0 ro ref-ов после перевода бакета в состоянии
\texttt{RECEIVING}.

Тут проблема в том, что бакет может читаться в состоянии \texttt{SENT/GARBAGE}.
Начали выполнять map\_callro прям перед окончанием переезда, успели зарефать на
реплике, откуда посылалось (т.е. до перевода из \texttt{SENDING} в
\texttt{SENT}), пришли на тот, куда прислалось, когда там бакет уже в
\texttt{ACTIVE}, получим дублирование данных.

\subsection*{Включение map_callro только по опции в конфигурации}

Предполагается, что \texttt{map_call} с \texttt{mode = 'read'} будет
использоваться редко, а потому нет смысла усложнять ребалансинг бакетов для
пользователей, которые не пользуются данной функцией. Для этого добавляется
новая опция конфигурирования vshard (будет проброшена в cartridge):
\texttt{enable_read_map_calls} (name subject to change) - опция может быть
задана на уровне репликасета или глобально в конфигурации (для всех
репликасетов сразу). Включает проверки собственного репликасета на ref-ы при
ребалансировке (пересылке бакетов и recovery). По умолчанию равна false.

Когда эта опция \texttt{false} на роутере, роутер будет сразу же возвращать
ошибку \texttt{UNSUPPORTED} (новая ошибка?), без запросов к репликам, при
попытке использовать любой \texttt{map_call} с \texttt{mode = 'read'}. Если же
на роутере она \texttt{true}, а на сторадже \texttt{false}, то реплика будет
возвращать эту ошибку когда роутер делает запрос. Чтобы \texttt{map_call} по
репликам работал, опция должна быть включена и на роутерах, и на стораджах.

Приняли решение отказаться от этой опции, чтобы всегда обеспечивать
максимальные проверки при ребалансинге.
